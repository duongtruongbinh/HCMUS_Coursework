{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSYvP0n8RjYH"
      },
      "source": [
        "# Lab02: Frequent itemset mining\n",
        "\n",
        "- Student ID: 21127229\n",
        "- Student name: Dương Trường Bình\n",
        "\n",
        "**How to do your homework**\n",
        "\n",
        "\n",
        "You will work directly on this notebook; the word `TODO` indicate the parts you need to do.\n",
        "\n",
        "You can discuss ideas with classmates as well as finding information from the internet, book, etc...; but *this homework must be your*.\n",
        "\n",
        "**How to submit your homework**\n",
        "\n",
        "Before submitting, rerun the notebook (`Kernel` ->` Restart & Run All`).\n",
        "\n",
        "Then create a folder named `ID` (for example, if your ID is 1234567, then name the folder `1234567`) Copy file notebook to this folder, compress and submit it on moodle.\n",
        "\n",
        "**Contents:**\n",
        "\n",
        "- Frequent itemset mining."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXZ5gCVaRjYa"
      },
      "source": [
        "# 1. Preliminaries\n",
        "## This is how it all started ...\n",
        "- Rakesh Agrawal, Tomasz Imielinski, Arun N. Swami: Mining Association Rules between Sets of Items in Large Databases. SIGMOD Conference 1993: 207-216\n",
        "- Rakesh Agrawal, Ramakrishnan Srikant: Fast Algorithms for Mining Association Rules in Large Databases. VLDB 1994: 487-499\n",
        "\n",
        "**These two papers are credited with the birth of Data Mining**\n",
        "## Frequent itemset mining (FIM)\n",
        "\n",
        "Find combinations of items (itemsets) that occur frequently.\n",
        "## Applications\n",
        "- Items = products, transactions = sets of products someone bought in one trip to the store.\n",
        "$\\Rightarrow$ items people frequently buy together.\n",
        "    + Example: if people usually buy bread and coffee together, we run a sale of bread to attract people attention and raise price of coffee.\n",
        "- Items = webpages, transactions = words. Unusual words appearing together in a large number of documents, e.g., “Brad” and “Angelina,” may indicate an interesting relationship.\n",
        "- Transactions = Sentences, Items = Documents containing those sentences. Items that appear together too often could represent plagiarism."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8vAJ8A2RjYi"
      },
      "source": [
        "## Transactional Database\n",
        "A transactional database $D$ consists of $N$ transactions: $D=\\left\\{T_1,T_2,...,T_N\\right\\}$. A transaction $T_n \\in D (1 \\le n \\le N)$ contains one or more items and that $I= \\left\\{ i_1,i_2,…,i_M \\right\\}$ is the set of distinct items in $D$, $T_n \\subset I$. Commonly, a transactional database is represented by a flat file instead of a database system: items are non-negative integers, each row represents a transaction, items in a transaction separated by space.\n",
        "\n",
        "Example:\n",
        "\n",
        "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29\n",
        "\n",
        "30 31 32\n",
        "\n",
        "33 34 35\n",
        "\n",
        "36 37 38 39 40 41 42 43 44 45 46\n",
        "\n",
        "38 39 47 48\n",
        "\n",
        "38 39 48 49 50 51 52 53 54 55 56 57 58\n",
        "\n",
        "32 41 59 60 61 62\n",
        "\n",
        "3 39 48\n",
        "\n",
        "63 64 65 66 67 68\n",
        "\n",
        "\n",
        "\n",
        "# Definition\n",
        "\n",
        "- Itemset: A collection of one or more items.\n",
        "    + Example: {1 4 5}\n",
        "- **k-itemset**: An itemset that contains k items.\n",
        "- Support: Frequency of occurrence of an itemset.\n",
        "    + Example: From the example above, item 3 appear in 2 transactions so its support is 2.\n",
        "- Frequent itemset: An itemset whose support is greater than or equal to a `minsup` threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdykKxr6RjY-"
      },
      "source": [
        "# The Apriori Principle\n",
        "- If an itemset is frequent, then all of its subsets must also be frequent.\n",
        "- If an itemset is not frequent, then all of its supersets cannot be frequent.\n",
        "- The support of an itemset never exceeds the support of its subsets.\n",
        "$$ \\forall{X,Y}: (X \\subseteq Y) \\Rightarrow s(X)\\ge s(Y)$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvfMR7-CRjZB"
      },
      "source": [
        "# 2. Implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9gZh4DORjZD"
      },
      "source": [
        "## The Apriori algorithm\n",
        "Suppose:\n",
        "\n",
        "$C_k$ candidate itemsets of size k.\n",
        "\n",
        "$L_k$ frequent itemsets of size k.\n",
        "\n",
        "The level-wise approach of Apriori algorithm can be descibed as follow:\n",
        "1. k=1, $C_k$ = all items.\n",
        "2. While $C_k$ not empty:\n",
        "    3. Scan the database to find which itemsets in $C_k$ are frequent and put them into $L_k$.\n",
        "    4. Use $L_k$ to generate a collection of candidate itemsets $C_{k+1}$ of size k+1.\n",
        "    5. k=k+1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF9xHOBLRjZJ"
      },
      "source": [
        "### Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7F0lUOSuRjZN"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OogwdcLRjZf"
      },
      "source": [
        "### Read data\n",
        "First we have to read data from database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2bsGrTERjZg"
      },
      "outputs": [],
      "source": [
        "\n",
        "def readData(path):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    --------------------------\n",
        "        path: path of database D.\n",
        "\n",
        "    --------------------------\n",
        "    Returns\n",
        "        data: a dictionary for representing database D\n",
        "                 - keys: transaction tids\n",
        "                 - values: itemsets.\n",
        "        s: support of distict items in D.\n",
        "    \"\"\"\n",
        "    data={}\n",
        "    s=defaultdict(lambda: 0) # Initialize a dictionary for storing support of items in I.\n",
        "    with open(path,'rt') as f:\n",
        "        tid=1;\n",
        "        for line in f:\n",
        "            itemset=set(map(int,line.split())) # a python set is a native way for storing an itemset.\n",
        "            for item in itemset:\n",
        "                s[item]+=1     #Why don't we compute support of items while reading data?\n",
        "            data[tid]= itemset\n",
        "            tid+=1\n",
        "\n",
        "    return data, s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSTC78WURjZu"
      },
      "source": [
        "### Tree Projection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGAkmuXtRjZw"
      },
      "source": [
        "**I gave you pseudo code of Apriori algorithm above but we implement Tree Projection. Tell me the differences of two algorithms.**\n",
        "\n",
        "\n",
        "**TODO:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVRT5BnWRjZz"
      },
      "outputs": [],
      "source": [
        "def joinset(a, b):\n",
        "    '''\n",
        "    Parameters\n",
        "    -------------------\n",
        "        2 itemsets a and b (of course they are at same branch in search space)\n",
        "\n",
        "    -------------------\n",
        "    return\n",
        "        ret: itemset generated by joining a and b\n",
        "    '''\n",
        "    # TODO (hint: this function will be called in generateSearchSpace method.):\n",
        "    return set(a).union(set(b))\n",
        "\n",
        "class TP:\n",
        "    def __init__(self, data=None, s=None, minSup=None):\n",
        "        self.data = data\n",
        "        self.s = {}\n",
        "\n",
        "        for key, support in sorted(s.items(), key=lambda item: item[1]):\n",
        "            self.s[key] = support\n",
        "        # TODO: why should we do this, answer it at the markdown below?\n",
        "\n",
        "        self.minSup = minSup\n",
        "        self.L = {}  # Store frequent itemsets mined from database\n",
        "        self.runAlgorithm()\n",
        "\n",
        "    def initialize(self):\n",
        "        \"\"\"\n",
        "        Initialize search space at first step\n",
        "        --------------------------------------\n",
        "        We represent our search space in a tree structure\n",
        "        \"\"\"\n",
        "        tree = {}\n",
        "\n",
        "        search_space = {}\n",
        "        for item, support in self.s.items():\n",
        "            search_space[item] = {}\n",
        "\n",
        "            search_space[item]['itemset'] = [item]\n",
        "            '''\n",
        "            python set does not remain elements order\n",
        "            so we use a list to extend it easily when create new itemset\n",
        "            but why we store itemset in data by a python set???? '''\n",
        "            # TODO: study about python set and its advantages,\n",
        "            # answer at the markdown below.\n",
        "\n",
        "            search_space[item]['pruned'] = False\n",
        "            # TODO:\n",
        "            # After finish implementing the algorithm tell me why should you use this\n",
        "            # instead of delete item directly from search_space and tree.\n",
        "\n",
        "            search_space[item]['support'] = support\n",
        "\n",
        "            tree[item] = {}\n",
        "            '''\n",
        "            Why should i store an additional tree (here it called tree)?\n",
        "            Answer: This really help in next steps.\n",
        "\n",
        "            Remember that there is always a big gap from theory to practicality\n",
        "            and implementing this algorithm in python is not as simple as you think.\n",
        "            '''\n",
        "\n",
        "        return tree, search_space\n",
        "\n",
        "    def computeItemsetSupport(self, itemset):\n",
        "\n",
        "        '''Return support of itemset'''\n",
        "        # TODO (hint: this is why i use python set in data)\n",
        "        support = 0\n",
        "        for tid, data in self.data.items():\n",
        "            if itemset.issubset(data):\n",
        "                support += 1\n",
        "        return support\n",
        "\n",
        "    def get_sub_tree(self, k, tree, search_space, itter_node):\n",
        "        if k == 0:\n",
        "            return search_space[itter_node]['support']\n",
        "        subtree = search_space[itter_node]\n",
        "        for node in subtree.keys():\n",
        "            k-=1\n",
        "            self.get_sub_tree(k,tree,search_space,node)\n",
        "\n",
        "\n",
        "    def prune(self, k, tree, search_space):\n",
        "\n",
        "        '''\n",
        "        In this method we will find out which itemset in current search space is frequent\n",
        "        itemset then add it to L[k]. In addition, we prune those are not frequent itemsets.\n",
        "        '''\n",
        "        if self.L.get(k) is None: self.L[k] = []\n",
        "        # TODO\n",
        "        for node in tree.keys():\n",
        "            if search_space[node]['support'] < self.minSup:\n",
        "                search_space[node]['pruned'] = True\n",
        "            else:\n",
        "                self.L[k].append(search_space[node]['itemset'])\n",
        "\n",
        "\n",
        "\n",
        "    def generateSearchSpace(self, k, tree, search_space):\n",
        "        '''\n",
        "        Generate search space for exploring k+1 itemset. (Recursive function)\n",
        "        '''\n",
        "        items = list(tree.keys())\n",
        "        ''' print search_space.keys() you will understand\n",
        "        why we need an additional tree, '''\n",
        "        l = len(items)\n",
        "        self.prune(k, tree, search_space)\n",
        "        if l == 0: return  # Stop condition\n",
        "        for i in range(l - 1):\n",
        "            sub_search_space = {}\n",
        "            sub_tree = {}\n",
        "            a = items[i]\n",
        "            if search_space[a]['pruned']: continue\n",
        "\n",
        "            for j in range(i + 1, l):\n",
        "                b = items[j]\n",
        "                search_space[a][b] = {}\n",
        "                tree[a][b] = {}\n",
        "                # You really need to understand what am i doing here before doing work below.\n",
        "                # (Hint: draw tree and search space to draft).\n",
        "\n",
        "                # TODO:\n",
        "                # First create newset using join set\n",
        "                newset = joinset(search_space[a]['itemset'], search_space[b]['itemset'])\n",
        "\n",
        "                # Second add newset to search_space\n",
        "                search_space[a][b] = {\n",
        "                    'itemset': newset,\n",
        "                    'pruned': False,\n",
        "                    'support': self.computeItemsetSupport(newset)\n",
        "                }\n",
        "            sub_search_space = search_space[a]\n",
        "            sub_tree = tree[a]\n",
        "\n",
        "            #  Generate search_space for k+1-itemset\n",
        "            self.generateSearchSpace(k + 1, sub_tree, sub_search_space)\n",
        "\n",
        "\n",
        "    def runAlgorithm(self):\n",
        "        tree, search_space = self.initialize()  # generate search space for 1-itemset\n",
        "        self.generateSearchSpace(1, tree, search_space)\n",
        "\n",
        "    def miningResults(self):\n",
        "        return self.L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tMTpwxLRjZ-"
      },
      "source": [
        "Ok, let's test on a typical dataset `chess`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLygYqiYRjZ-"
      },
      "outputs": [],
      "source": [
        "data, s= readData('chess.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnxbU77YRjaF",
        "outputId": "c3b158be-6b46-4a3c-9b71-6a92d3d31ded"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: [[48], [56], [66], [34], [62], [7], [36], [60], [40], [29], [52], [58]], 2: [{48, 52}, {48, 58}, {56, 29}, {56, 52}, {56, 58}, {66, 60}, {66, 29}, {66, 52}, {66, 58}, {40, 34}, {34, 29}, {34, 52}, {34, 58}, {60, 62}, {40, 62}, {29, 62}, {52, 62}, {58, 62}, {60, 7}, {40, 7}, {29, 7}, {52, 7}, {58, 7}, {36, 60}, {40, 36}, {36, 29}, {36, 52}, {58, 36}, {40, 60}, {60, 29}, {60, 52}, {58, 60}, {40, 29}, {40, 52}, {40, 58}, {52, 29}, {58, 29}, {58, 52}], 3: [{48, 58, 52}, {56, 52, 29}, {56, 58, 29}, {56, 58, 52}, {66, 60, 29}, {66, 60, 52}, {66, 60, 58}, {66, 52, 29}, {66, 58, 29}, {66, 52, 58}, {40, 34, 29}, {40, 34, 52}, {40, 34, 58}, {34, 52, 29}, {34, 58, 29}, {34, 52, 58}, {60, 29, 62}, {60, 62, 52}, {58, 60, 62}, {40, 29, 62}, {40, 52, 62}, {40, 58, 62}, {52, 29, 62}, {58, 29, 62}, {58, 52, 62}, {40, 60, 7}, {60, 29, 7}, {60, 52, 7}, {58, 60, 7}, {40, 29, 7}, {40, 52, 7}, {40, 58, 7}, {52, 29, 7}, {58, 29, 7}, {58, 52, 7}, {40, 36, 60}, {36, 29, 60}, {36, 60, 52}, {58, 36, 60}, {40, 36, 29}, {40, 36, 52}, {40, 58, 36}, {36, 29, 52}, {58, 36, 29}, {58, 36, 52}, {40, 60, 29}, {40, 60, 52}, {40, 58, 60}, {60, 29, 52}, {58, 60, 29}, {58, 60, 52}, {40, 52, 29}, {40, 58, 29}, {40, 58, 52}, {58, 52, 29}], 4: [{52, 56, 58, 29}, {66, 52, 60, 29}, {66, 58, 60, 29}, {66, 52, 58, 60}, {66, 52, 58, 29}, {34, 52, 40, 29}, {34, 40, 58, 29}, {34, 52, 40, 58}, {34, 52, 58, 29}, {58, 60, 29, 62}, {52, 58, 60, 62}, {52, 40, 29, 62}, {40, 58, 29, 62}, {52, 40, 58, 62}, {52, 58, 29, 62}, {7, 40, 58, 60}, {52, 7, 60, 29}, {7, 58, 60, 29}, {52, 7, 58, 60}, {52, 7, 40, 29}, {7, 40, 58, 29}, {52, 7, 40, 58}, {52, 7, 58, 29}, {36, 40, 60, 29}, {36, 52, 40, 60}, {36, 40, 58, 60}, {36, 52, 60, 29}, {36, 58, 60, 29}, {36, 52, 58, 60}, {36, 52, 40, 29}, {36, 40, 58, 29}, {36, 52, 40, 58}, {36, 52, 58, 29}, {52, 40, 60, 29}, {40, 58, 60, 29}, {52, 40, 58, 60}, {52, 58, 60, 29}, {52, 40, 58, 29}], 5: [{66, 52, 58, 60, 29}, {34, 40, 52, 58, 29}, {40, 52, 58, 29, 62}, {7, 52, 58, 60, 29}, {7, 40, 52, 58, 29}, {36, 40, 52, 60, 29}, {36, 40, 58, 60, 29}, {36, 40, 52, 58, 60}, {36, 52, 58, 60, 29}, {36, 40, 52, 58, 29}, {40, 52, 58, 60, 29}], 6: [{36, 40, 52, 58, 60, 29}]}\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "a=TP(data=data,s=s, minSup=3000)\n",
        "print(a.miningResults())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp0RFbw-RjaU"
      },
      "source": [
        "### Answer questions here:\n",
        "\n",
        "**why should we do sort**\n",
        "\n",
        "Trả lời:\n",
        "\n",
        "Trong hàm `__init__` của class `TP` ta đã dùng hàm `sorted` để sắp xếp các phần tử của dictionary `s` tăng dần theo support của chúng, đảm bảo rằng các itemset có support nhỏ hơn sẽ được xử lý trước. Việc sắp xếp này giúp cải thiện hiệu suất của thuật toán vì chúng ta có thể tỉa bớt các node không thỏa minsup trước mà không sinh ra các nhánh con không cần thiết từ đó giảm bớt thời gian xử lý. Chúng ta đã lưu kết quả sắp xếp vào biến `self.s` để dễ dàng truy cập và sử dụng trong các hàm ở các bước tiếp theo.\n",
        "\n",
        "**study about python set and its advantages ?**\n",
        "\n",
        "Trả lời:\n",
        "\n",
        "`Set` trong Python là một cấu trúc dữ liệu không có thứ tự, không thể thay đổi và không chứa các phần tử trùng lặp. Một số ưu điểm của `set` so với các cấu trúc dữ liệu khác như `list` là:\n",
        "\n",
        "- Tốc độ truy cập nhanh: Ta có thể truy cập một phần tử thông qua các key mà không cần index như `list`. Thời gian truy cập của `set` là O(1) trong khi của `list` là O(n).\n",
        "\n",
        "- Các phép toán set: `set` hỗ trợ nhiều phép toán của tập hợp như union, intersection, difference, ... giúp giảm thiểu thời gian xử lý so với việc sử dụng `list`. Trong đó, phép toán `union` giữa hai `set` là rất nhanh chóng và đã được ta dùng trong hàm `joinset` để kết hợp các k-itemset thành k+1-itemset.\n",
        "\n",
        "- Loại bỏ các phần tử trùng lặp: nếu thêm một phần tử đã tồn tại vào `set`, nó sẽ không thêm vào mà giữ nguyên giá trị cũ (cũng góp phần trong việc kết hợp các itemset trong hàm `joinset`).\n",
        "\n",
        "- `Set` thích hợp cho việc kiểm tra sự tồn tại của một phần tử trong một tập hợp lớn và ta đã sử dụng `set` trong việc tính toán support của các itemset (hàm `computeItemsetSupport`) với hàm `issubset` để kiểm tra xem itemset có tồn tại trong một transaction hay không một cách nhanh hơn nhiều so với việc sử dụng `list`.\n",
        "\n",
        "**After finish implementing the algorithm tell me why should you use this? Instead of delete item directly from search_space and tree.**\n",
        "\n",
        "Trả lời:\n",
        "\n",
        "Vì điều này giúp ta duy trì cấu trúc của `search_space` và `tree` nguyên vẹn (có thể hữu ích trong việc debug và giúp duy trì tính toàn vẹn dữ liệu). Ngoài ra, việc xóa phần tử trực tiếp từ `search_space` và `tree` có thể gây ra lỗi trong quá trình duyệt và xử lý dữ liệu, đặc biệt là trong các bước tiếp theo của thuật toán. Thay vì xóa trực tiếp, việc đánh dấu chúng là \"pruned\" giúp tiết kiệm thời gian xử lý và giảm thiểu lỗi.\n",
        "\n",
        "\n",
        "**Apriori algorithm and Tree Projection, tell me the differences of two algorithms.**\n",
        "\n",
        "Trả lời:\n",
        "\n",
        "|-|Apriori algorithm|Tree Projection|\n",
        "|-|-----------------|---------------|\n",
        "|Cách tiếp cận| Sử dụng phương pháp tìm kiếm theo cấp độ (level-wise approach) để tạo ra tất cả các itemset ở level k+1 từ các itemset ở level k trước khi kiểm tra support của chúng.| Tiếp cận dựa trên cấu trúc cây, sinh ra tất cả các tập con có thể của level k+1 có chung tiền tố tại node N trước khi kiểm tra support của chúng.|\n",
        "|Ý tưởng duyệt|Ý tưởng giống thuật toán BFS (Breadth-First Search), duyệt qua từng level k trước khi tiếp tục sang level k+1|Ý tưởng giống thuật toán DFS (Depth-First Search), tại mỗi node X ở level k, ta duyệt sâu vào tất cả các tập con có thể của level k+1 có chung tiền tố với X trước khi xem xét các node khác ở level k|\n",
        "|Kiểm tra điều kiện join|Cần kiểm tra các item từ 1 đến k-1 của các tập con ở level k trước khi join 2 tập con lại để tạo ra tập con có k+1 item|Do lưu trữ một cây tiền tố, không cần kiểm tra điều kiện như Apriori mà vẫn có thể sinh ra được tất cả các tập con tiếp theo|\n",
        "|Đặc điểm|Dễ hiểu, dễ cài đặt, và có thể cài đặt song song (parallelize)|Dễ hiểu nhưng cài đặt phức tạp hơn so với Apriori, không thể cài đặt song song nhưng có thể có hiệu suất cao hơn khi xử lý dữ liệu lớn do sử dụng cấu trúc cây tìm kiếm|\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnVm8wYIRjaV"
      },
      "source": [
        "# 3. Churn analysis\n",
        "\n",
        "In this section, you will use frequent itemset mining technique to analyze `churn` dataset (for any purposes).\n",
        "\n",
        "*Remember this dataset is not represented as a transactional database, first thing that you have to do is transforming it into a flat file."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tìm hiểu dataset churn\n",
        "\n",
        "Mỗi dòng trong dataset mô tả thông tin của khách hàng, các dịch vụ họ sử dụng và họ ngừng sử dụng dịch vụ của công ty hay không\n",
        "\n",
        "Ta sẽ dùng thuật toán khai thác tập phổ biến để tìm các đặc trưng thường xuất hiện ở các khách hàng ngừng (không ngừng) sử dụng dịch vụ của công ty\n",
        "\n",
        "#### Đọc dữ liệu\n",
        "\n",
        "Vì file `churn.txt` chưa phải là một transaction database nên ta sẽ phải đưa dữ liệu về dạng transaction lúc đọc data.\n",
        "\n",
        "\n",
        "Hàm đọc dữ liệu sẽ xem mỗi dòng là một transaction, mỗi thuộc tính trong dòng là 1 item nhưng có thêm tiền tố là tên của thuộc tính phía trước\n",
        "Ví dụ 1 transaction có 2 thuộc tính `Phone`,`Area Code` có giá trị lần lượt là '1234' và '150' sẽ được chuyển đổi thành: ['Phone=1234', 'Area Code= 150']"
      ],
      "metadata": {
        "id": "WiLkwZ1DpzBg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTKLW-ETpjfe"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# YOUR CODE HERE\n",
        "\n",
        "def readChurn(path):\n",
        "    data = {}\n",
        "    s = defaultdict(lambda: 0)\n",
        "    with open(path, 'rt') as f:\n",
        "        columns = f.readline().strip().split(',')\n",
        "        for tid, line in enumerate(f, start=1):\n",
        "            itemset = line.strip().split(',')\n",
        "            data[tid] = set(f'{column}={item}' for column, item in zip(columns, itemset))\n",
        "            for item in data[tid]:\n",
        "                s[item] += 1\n",
        "    return data, s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfYmg6JRpjff"
      },
      "outputs": [],
      "source": [
        "transactions, s = readChurn('churn.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sau khi đã đọc dữ liệu về đúng theo dạng transaction, ta sẽ dùng lại thuật toán Tree Projection ở trên để khai thác tập phổ biến. Ta sẽ tạm thời gán minsup=500 và xem kết quả"
      ],
      "metadata": {
        "id": "qzhqpxivrDCX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJvYhbFrpjfg",
        "outputId": "1a74806c-8fdb-442e-f533-4fbcd7a0863f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frequent 1-itemsets:\n",
            "['Intl Calls=4']\n",
            "['Intl Calls=3']\n",
            "['CustServ Calls=0']\n",
            "['CustServ Calls=2']\n",
            "['Area Code=408']\n",
            "['Area Code=510']\n",
            "['VMail Plan=yes']\n",
            "['CustServ Calls=1']\n",
            "['Area Code=415']\n",
            "['VMail Message=0']\n",
            "['VMail Plan=no']\n",
            "['Churn?=False.']\n",
            "[\"Int'l Plan=no\"]\n",
            "\n",
            "Frequent 2-itemsets:\n",
            "{'Intl Calls=4', 'Churn?=False.'}\n",
            "{\"Int'l Plan=no\", 'Intl Calls=4'}\n",
            "{'Intl Calls=3', 'Churn?=False.'}\n",
            "{\"Int'l Plan=no\", 'Intl Calls=3'}\n",
            "{'VMail Message=0', 'CustServ Calls=0'}\n",
            "{'CustServ Calls=0', 'VMail Plan=no'}\n",
            "{'Churn?=False.', 'CustServ Calls=0'}\n",
            "{\"Int'l Plan=no\", 'CustServ Calls=0'}\n",
            "{'VMail Message=0', 'CustServ Calls=2'}\n",
            "{'VMail Plan=no', 'CustServ Calls=2'}\n",
            "{'Churn?=False.', 'CustServ Calls=2'}\n",
            "{\"Int'l Plan=no\", 'CustServ Calls=2'}\n",
            "{'VMail Message=0', 'Area Code=408'}\n",
            "{'VMail Plan=no', 'Area Code=408'}\n",
            "{'Churn?=False.', 'Area Code=408'}\n",
            "{\"Int'l Plan=no\", 'Area Code=408'}\n",
            "{'Area Code=510', 'VMail Message=0'}\n",
            "{'Area Code=510', 'VMail Plan=no'}\n",
            "{'Area Code=510', 'Churn?=False.'}\n",
            "{\"Int'l Plan=no\", 'Area Code=510'}\n",
            "{'Churn?=False.', 'VMail Plan=yes'}\n",
            "{\"Int'l Plan=no\", 'VMail Plan=yes'}\n",
            "{'CustServ Calls=1', 'Area Code=415'}\n",
            "{'VMail Message=0', 'CustServ Calls=1'}\n",
            "{'CustServ Calls=1', 'VMail Plan=no'}\n",
            "{'CustServ Calls=1', 'Churn?=False.'}\n",
            "{\"Int'l Plan=no\", 'CustServ Calls=1'}\n",
            "{'VMail Message=0', 'Area Code=415'}\n",
            "{'VMail Plan=no', 'Area Code=415'}\n",
            "{'Churn?=False.', 'Area Code=415'}\n",
            "{\"Int'l Plan=no\", 'Area Code=415'}\n",
            "{'VMail Message=0', 'VMail Plan=no'}\n",
            "{'VMail Message=0', 'Churn?=False.'}\n",
            "{\"Int'l Plan=no\", 'VMail Message=0'}\n",
            "{'Churn?=False.', 'VMail Plan=no'}\n",
            "{\"Int'l Plan=no\", 'VMail Plan=no'}\n",
            "{\"Int'l Plan=no\", 'Churn?=False.'}\n",
            "\n",
            "Frequent 3-itemsets:\n",
            "{\"Int'l Plan=no\", 'Intl Calls=3', 'Churn?=False.'}\n",
            "{'VMail Message=0', 'CustServ Calls=0', 'VMail Plan=no'}\n",
            "{\"Int'l Plan=no\", 'Churn?=False.', 'CustServ Calls=0'}\n",
            "{'VMail Message=0', 'VMail Plan=no', 'CustServ Calls=2'}\n",
            "{\"Int'l Plan=no\", 'Churn?=False.', 'CustServ Calls=2'}\n",
            "{'VMail Message=0', 'VMail Plan=no', 'Area Code=408'}\n",
            "{'VMail Message=0', 'Churn?=False.', 'Area Code=408'}\n",
            "{\"Int'l Plan=no\", 'VMail Message=0', 'Area Code=408'}\n",
            "{'Churn?=False.', 'VMail Plan=no', 'Area Code=408'}\n",
            "{\"Int'l Plan=no\", 'VMail Plan=no', 'Area Code=408'}\n",
            "{\"Int'l Plan=no\", 'Churn?=False.', 'Area Code=408'}\n",
            "{'Area Code=510', 'VMail Message=0', 'VMail Plan=no'}\n",
            "{'Area Code=510', 'VMail Message=0', 'Churn?=False.'}\n",
            "{\"Int'l Plan=no\", 'Area Code=510', 'VMail Message=0'}\n",
            "{'Area Code=510', 'Churn?=False.', 'VMail Plan=no'}\n",
            "{\"Int'l Plan=no\", 'Area Code=510', 'VMail Plan=no'}\n",
            "{\"Int'l Plan=no\", 'Area Code=510', 'Churn?=False.'}\n",
            "{\"Int'l Plan=no\", 'Churn?=False.', 'VMail Plan=yes'}\n",
            "{'CustServ Calls=1', 'Churn?=False.', 'Area Code=415'}\n",
            "{\"Int'l Plan=no\", 'CustServ Calls=1', 'Area Code=415'}\n",
            "{'VMail Message=0', 'CustServ Calls=1', 'VMail Plan=no'}\n",
            "{'VMail Message=0', 'CustServ Calls=1', 'Churn?=False.'}\n",
            "{'VMail Message=0', 'CustServ Calls=1', \"Int'l Plan=no\"}\n",
            "{'CustServ Calls=1', 'VMail Plan=no', 'Churn?=False.'}\n",
            "{\"Int'l Plan=no\", 'CustServ Calls=1', 'VMail Plan=no'}\n",
            "{\"Int'l Plan=no\", 'CustServ Calls=1', 'Churn?=False.'}\n",
            "{'VMail Message=0', 'VMail Plan=no', 'Area Code=415'}\n",
            "{'VMail Message=0', 'Churn?=False.', 'Area Code=415'}\n",
            "{\"Int'l Plan=no\", 'VMail Message=0', 'Area Code=415'}\n",
            "{'Churn?=False.', 'VMail Plan=no', 'Area Code=415'}\n",
            "{\"Int'l Plan=no\", 'VMail Plan=no', 'Area Code=415'}\n",
            "{\"Int'l Plan=no\", 'Churn?=False.', 'Area Code=415'}\n",
            "{'VMail Message=0', 'VMail Plan=no', 'Churn?=False.'}\n",
            "{\"Int'l Plan=no\", 'VMail Message=0', 'VMail Plan=no'}\n",
            "{\"Int'l Plan=no\", 'VMail Message=0', 'Churn?=False.'}\n",
            "{\"Int'l Plan=no\", 'Churn?=False.', 'VMail Plan=no'}\n",
            "\n",
            "Frequent 4-itemsets:\n",
            "{'VMail Message=0', 'VMail Plan=no', 'Area Code=408', 'Churn?=False.'}\n",
            "{\"Int'l Plan=no\", 'VMail Message=0', 'VMail Plan=no', 'Area Code=408'}\n",
            "{'VMail Message=0', 'VMail Plan=no', 'Area Code=510', 'Churn?=False.'}\n",
            "{\"Int'l Plan=no\", 'VMail Message=0', 'VMail Plan=no', 'Area Code=510'}\n",
            "{'VMail Message=0', 'VMail Plan=no', 'CustServ Calls=1', 'Churn?=False.'}\n",
            "{\"Int'l Plan=no\", 'VMail Message=0', 'VMail Plan=no', 'CustServ Calls=1'}\n",
            "{\"Int'l Plan=no\", 'VMail Message=0', 'CustServ Calls=1', 'Churn?=False.'}\n",
            "{\"Int'l Plan=no\", 'VMail Plan=no', 'CustServ Calls=1', 'Churn?=False.'}\n",
            "{'VMail Message=0', 'VMail Plan=no', 'Area Code=415', 'Churn?=False.'}\n",
            "{\"Int'l Plan=no\", 'VMail Message=0', 'VMail Plan=no', 'Area Code=415'}\n",
            "{\"Int'l Plan=no\", 'VMail Message=0', 'Area Code=415', 'Churn?=False.'}\n",
            "{\"Int'l Plan=no\", 'VMail Plan=no', 'Area Code=415', 'Churn?=False.'}\n",
            "{\"Int'l Plan=no\", 'VMail Message=0', 'VMail Plan=no', 'Churn?=False.'}\n",
            "\n",
            "Frequent 5-itemsets:\n",
            "{\"Int'l Plan=no\", 'VMail Message=0', 'VMail Plan=no', 'CustServ Calls=1', 'Churn?=False.'}\n",
            "{\"Int'l Plan=no\", 'VMail Message=0', 'VMail Plan=no', 'Area Code=415', 'Churn?=False.'}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Run the algorithm and print the results\n",
        "a=TP(data=transactions,s=s, minSup=500)\n",
        "for k, itemsets in a.miningResults().items():\n",
        "    print(f'Frequent {k}-itemsets:')\n",
        "    for itemset in itemsets:\n",
        "        print(itemset)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vậy với minsup=500 ta đã khai thác được các tập phổ biến trên\n",
        "\n",
        "Ta có thể giải thích kết quả của 2 tập phổ biến ở 5-itemsets:\n",
        "\n",
        "- Các khách hàng mà không dùng dịch vụ quốc tế, không có lời nhắn thoại nào, không dùng voice mail,  có 1 cuộc gọi đến dịch vụ khách hàng thì thường sẽ ngừng dùng dịch vụ của công ty\n",
        "\n",
        "- Các khách hàng mà không dùng dịch vụ quốc tế, không có lời nhắn thoại nào, không dùng voice mail,  có mã vùng là 415 thì thường sẽ ngừng dùng dịch vụ của công ty\n",
        "\n",
        "Ngoài ra ta có thể tùy chỉnh các ngưỡng minsup khác để xem xét các quả phù hợp khác nhau cho các minsup đó."
      ],
      "metadata": {
        "id": "RUj_e9mgrTBc"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}