{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01: Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Student ID: \n",
    "- Student name: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do your homework\n",
    "\n",
    "To finish the project, fill in:\n",
    "- ```YOUR CODE HERE``` in code cells\n",
    "\n",
    "- ```YOUR ANSWER HERE``` in text cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "\n",
    "- Your project must be finished by your own self. You may discuss with the others, but must not copy (partially or entirely) their codes or solutions. You will receive a <font color='red'>0 point</font> for this project if you violate this plagiarism rule. \n",
    "- Because our plagiarism checker is very sensitive, if the plagiarism check result is <font color='red'>greater than 60%</font>, your work will receive <font color='red'>0 point</font>. Therefore we will not deal with plagiarism cases.\n",
    "\n",
    "- You can create new cells to clarify your code / answer, however, please <font color='red'>do not delete any pre-defined code cells or test case cells</font> as it may affect the grading results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to submit\n",
    "\n",
    "In the grading stage, I will first select `Kernel` - `Restart Kernel & Run All Cells` to restart and run all cells in your notebook. As a result, before submitting your project, you should run `Kernel` - `Restart Kernel & Run All Cells` to ensure your code will run as you expect.\n",
    "\n",
    "After that, rename your notebook as `ID1.ipynb` (e.g. `19123.ipynb`) and submit on Moodle.\n",
    "\n",
    "<font color=yellow>Please follow the above submission guidelines. Any violation of these instructions may cost you some penalty points (0-50%)!!!</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "- Data pre-processing techniques.\n",
    "    - Exploring your data (2 pts)\n",
    "    - Encoding categorical (2 pts)\n",
    "    - Discretization techniques (2 pts)\n",
    "    - Outlier handling techniques (1 pts)\n",
    "    - Feature scaling techniques (2 pts)\n",
    "    - Clean submission (1 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libs\n",
    "**Note:** <span style=\"color:yellow\">All packages you can use in this lab are imported in the cell below. Please don't modify this, just run that.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from zlib import adler32\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import KBinsDiscretizer, LabelEncoder, StandardScaler, MinMaxScaler, MaxAbsScaler, Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config matplotlib and pandas display\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 100) # For clearly\n",
    "pd.set_option('display.max_columns', None) # For clearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config seaborn\n",
    "plt.rcParams[\"figure.figsize\"] = [12, 8]\n",
    "\n",
    "custom = {\"axes.edgecolor\": \"blue\", \"grid.linestyle\": \"dashed\", \"grid.color\": \"black\"}\n",
    "sns.set_style(\"whitegrid\", rc = custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Python virtual env\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring your data (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read rawdata from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many rows and how many columns does the raw data have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you calculate the number of rows and columns of the DataFrame `raw_df` and store it in the variable `shape` (tuple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert adler32(str(np.sqrt(shape[0] * shape[1])).encode()) == 590480314"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does each line mean? Does it matter if the lines have different meanings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: \n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the raw data have duplicate rows?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you calculate the number of rows with duplicate indexes and store it in the variable `num_duplicated_rows`. In a group of lines with the same index, the first line is not counted as repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert adler32(str(num_duplicated_rows).encode()) == 3211313"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does each column mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the meaning of each column:\n",
    "- First, you need to read the file \"metadata.json\" in the `data` folder into DataFrame `metadata`;\n",
    "- Then, you describe what suitable datatype for each column? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Describe datatype**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving forward, you should read the results displayed above and make sure you understand the meaning of the columns. To understand the meaning of the column, you may need to look at the values of the DataFrame side column `raw_df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What data type does each column currently have? Are there any columns whose data types are not suitable for further processing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you calculate the data type (dtype) of each column in DataFrame `raw_df` and save the result into Series `dtypes` (This Series has the index as the column name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "dtypes = raw_df.dtypes\n",
    "\n",
    "int_cols = set(dtypes[(dtypes==np.int32) | (dtypes==np.int64)].index)\n",
    "assert adler32(str(len(int_cols)).encode()) == 3276850\n",
    "\n",
    "float_cols = set(dtypes[(dtypes==np.float32) | (dtypes==np.float64)].index)\n",
    "assert adler32(str(len(float_cols)).encode()) == 3473461\n",
    "\n",
    "object_cols = set(dtypes[dtypes == object].index)\n",
    "assert adler32(str(len(object_cols)).encode()) == 9830500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert datatype for UCT times attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datatype of the column `uct_time` should be datetime. You have to convert it to the right datatype. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "raw_df[\"uct_time\"].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the remain columns, we will process later. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring datetime attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_col_df = raw_df.select_dtypes(include=['datetime64','datetime64[ns, UTC]'])\n",
    "datetime_col_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "df_plot = raw_df.copy()\n",
    "df_plot[\"year\"] = raw_df['uct_time'].dt.year\n",
    "df_plot = df_plot.groupby(['outcome', 'year']).size().reset_index().pivot(columns='outcome', index='year', values=0)\n",
    "df_plot.plot(kind='bar', stacked=True)\n",
    "plt.title(\"Outcome over years (2006 - 2022) of spaceX rocket launch.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Describe your observation from chart**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring numerical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col_df = raw_df.select_dtypes(exclude=['object', 'datetime64','datetime64[ns, UTC]'])\n",
    "num_col_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For columns with numeric data types, you will calculate:\n",
    "- Percentage (from 0 to 100) of missing values\n",
    "- Min value\n",
    "- Lower quantile\n",
    "- Median value\n",
    "- Upper quantile\n",
    "- Max value\n",
    "\n",
    "You will save the results to a DataFrame `num_col_info_df`, where:\n",
    "- The names of the columns are the names of the numeric columns in `raw_df`\n",
    "- Names of rows: \"missing_ratio\", \"min\", \"lower_quartile\", \"median\", \"upper_quartile\", \"max\"  \n",
    "\n",
    "For ease of viewing, you round all values to 1 decimal place using the `.round(1)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_ratio(s):\n",
    "    # TODO:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def median(df):\n",
    "    # TODO:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def lower_quartile(df):\n",
    "    # TODO:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def upper_quartile(df):\n",
    "    # TODO:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "num_col_info_df = num_col_df.agg([missing_ratio, \"min\", lower_quartile, median, upper_quartile, \"max\"])\n",
    "num_col_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an attribute has missing ratio greater than 70%, you can consider to drop it from dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "num_col_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the otherwise case, you have to fill missing values. To deal with missing values, you have to perform mean fill, median fill, and mode fill. Then, you study how different they are by using the visualization of probability density function (p.d.f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "## Mean fill\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "## Median fill\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "## Mode fill\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization for rocket_height\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "num_col_df[\"rocket_height\"] .plot(kind=\"kde\", ax=ax, color=\"blue\")\n",
    "num_col_df[\"mean_fill_rocket_height\"] .plot(kind=\"kde\", ax=ax, color=\"red\")\n",
    "num_col_df[\"median_fill_rocket_height\"] .plot(kind=\"kde\", ax=ax, color=\"green\")\n",
    "num_col_df[\"mode_fill_rocket_height\"] .plot(kind=\"kde\", ax=ax, color=\"yellow\")\n",
    "\n",
    "lines, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(lines, labels, loc='best')\n",
    "plt.title(\"Comparing mean, median, and mode missing values filling for rocket height.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Describe your observation from chart**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before choosing one of them to fill in your `raw_df`**, do you realize an abnomal in `rocket_height` attribute?\n",
    "\n",
    "**TODO:** Read metadata again, check `rocket_name`, find the way to fill missing value for `rocket_height`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "## Recheck: find unique elements in `rocket_name`\n",
    "raw_df[\"rocket_name\"].unique()\n",
    "\n",
    "## Check the maximum and minimum height values for each rocket\n",
    "def checking_range(rocket_name: str) -> tuple[float, float]:\n",
    "    \"\"\"Checking range of height for a given rocket name\n",
    "\n",
    "    Args:\n",
    "        rocket_name (str): the name of rocket\n",
    "\n",
    "    Returns:\n",
    "        tuple[float, float]: the range, min-max.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform checking for Falcon 1\n",
    "assert adler32(str(checking_range(rocket_name=\"Falcon 1\")[0] + checking_range(rocket_name=\"Falcon 1\")[1]).encode()) == 33620172"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform checking for Falcon 9\n",
    "assert adler32(str(checking_range(rocket_name=\"Falcon 9\")[0] + checking_range(rocket_name=\"Falcon 9\")[1]).encode()) == 48627956"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform checking for Falcon Heavy\n",
    "assert adler32(str(checking_range(rocket_name=\"Falcon Heavy\")[0] * checking_range(rocket_name=\"Falcon Heavy\")[1]).encode()) == 70713644"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, you should fill missing values with a specific value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# YOUR CODE HERE\n",
    "def fill_rocketheight(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    cp_df = df.copy()\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    return cp_df\n",
    "\n",
    "raw_df = fill_rocketheight(raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose one of ways (mean fill, median fill) to fill missing values for the remain columns (`rocket_diameter`, and `rocket_mass`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "num_col_df = raw_df.select_dtypes(exclude=['object', 'datetime64','datetime64[ns, UTC]'])\n",
    "num_col_df.agg([missing_ratio, \"min\", lower_quartile, median, upper_quartile, \"max\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "num_col_info_df = num_col_df.agg([missing_ratio, \"min\", lower_quartile, median, upper_quartile, \"max\"])\n",
    "assert num_col_info_df.shape == (6, 4)\n",
    "\n",
    "data = num_col_info_df.loc[['missing_ratio', 'min', 'lower_quartile', 'median', 'upper_quartile', 'max'],\n",
    "                           ['rocket_boosters', 'rocket_height', 'rocket_diameter', 'rocket_mass']].values\n",
    "\n",
    "assert adler32(str(data).encode()) == 1580417893"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** What type of each numerical attribute? Continous?  variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring non-numerical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_col_df = raw_df.select_dtypes(include=['object'])\n",
    "cate_col_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2dict(s: str) -> List[Dict]:\n",
    "    \"\"\"Convert given string to dict\n",
    "    \n",
    "    Example:\n",
    "        - Input string: [{'type': 'Satellite', 'mass': None, 'orbit': 'LEO'}, {'type': 'Satellite', 'mass': None, 'orbit': 'LEO'}]\n",
    "        - Output: ({'type': 'Satellite', 'mass': None, 'orbit': 'LEO'}, {'type': 'Satellite', 'mass': None, 'orbit': 'LEO'})\n",
    "\n",
    "\n",
    "    Args:\n",
    "        s (str): _description_\n",
    "        \n",
    "    Return:\n",
    "        list(dict):\n",
    "    \"\"\"\n",
    "    # TODO:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series and DataFrame methods define a .explode() method that explodes lists into separate rows. You should use this method to explode the `payloads` attribute and convert this column to `str`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For columns with non-numeric data types, you calculate:\n",
    "- Percentage (from 0 to 100) of missing values\n",
    "- Number of values (the values here are different values and we do not consider missing values): with columns whose type is categorical, it is a set with a finite number of categories. Directly counting the number of values in these columns doesn't make much sense, so it's better to count the number of elements of all types.\n",
    "- The percentage (from 0 to 100) of each value is sorted by decreasing percentage (we do not consider missing values, the ratio is the ratio compared to the number of non-missing values): you use a dictionary to store , key is the value, value is the percentage; With the column corresponding to each type, the method is similar to above.\n",
    "\n",
    "You will save the results to DataFrame `cat_col_info_df`, where:\n",
    "- The names of the columns are the names of the non-numeric columns in `raw_df`\n",
    "- The names of the lines are: \"missing_ratio\", \"num_values\", \"value_ratios\"\n",
    "\n",
    "For ease of viewing, you round all values to 1 decimal place using the `.round(1)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_ratio(s):\n",
    "    # TODO:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def num_values(s):\n",
    "    # TODO:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def value_ratios(s):\n",
    "    # TODO:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "cat_col_info_df = cate_col_df.agg([missing_ratio, num_values, value_ratios])\n",
    "cat_col_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "c = cat_col_info_df['landpad_name']\n",
    "assert adler32(str(c.loc['missing_ratio']).encode()) == 33554635\n",
    "assert adler32(str(c.loc['num_values']).encode()) == 3604535\n",
    "\n",
    "c = cat_col_info_df['landpad_type']\n",
    "assert adler32(str(c.loc['missing_ratio']).encode()) == 33161421\n",
    "assert adler32(str(c.loc['num_values']).encode()) == 3407924\n",
    "\n",
    "c = cat_col_info_df['landpad_region']\n",
    "assert adler32(str(c.loc['missing_ratio']).encode()) == 34144462\n",
    "assert adler32(str(c.loc['num_values']).encode()) == 3342387"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we will fill in the missing value for these non-attributes. You make a list of attributes that need to be filled in here.\n",
    "- `landpad_name`\n",
    "- `landpad_type`\n",
    "- `landpad_region`\n",
    "\n",
    "Considering the missing ratio, should we delete these attribute columns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you have to check `landpad_name`, `landpad_type`, and `landpad_region`. If these values are ALL NAN, you should these row from your `cate_col_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "cate_col_df[cate_col_df[\"landpad_name\"].isnull() & cate_col_df[\"landpad_type\"].isnull() & cate_col_df[\"landpad_region\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "cat_col_info_df = cate_col_df.agg([missing_ratio, num_values, value_ratios])\n",
    "cat_col_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Considering the Falcon 1 rockets, what are the names, types, and regions of their landpad? Comparing their names of launch pad and launch region. Similarly, you check for Falcon 9 and Falcon Heavy rockets, give your observation, and fill in the missing value with some specific values.\n",
    "\n",
    "*Hint*: It can be said that the region of the landing pad and launch pad are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Googling, you can find something interesting about the region of each landpad. Please fill the table below:\n",
    "\n",
    "TODO: Complete the table below.\n",
    "\n",
    "| Landpad  | Type  |  Region |\n",
    "|---|---|---|\n",
    "| OCISLY  | ASDS  |   |\n",
    "| JRTI  | ASDS  | Florida  |\n",
    "| ASOG  |   |  Port Canaveral, Florida  |\n",
    "| LZ-1  |  RTLS |  |\n",
    "| LZ-4  |   | California  |\n",
    "| JRTI-1  |   |   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation 1**: \n",
    "- Falcon 9 rockets which have launchpad in Florida and have landpad in Florida that have no missing values. \n",
    "- Falcon 9 rockets which have launchpad in Florida and have landpad in California that have no missing values. Their land name and type are OCISLY and ASDS, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: What are the further rules you can find?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation 2**\n",
    "- Falcon 9 rockets which have landpad name is `OCISLY`, and landpad type is `ASDS` => landpad region `California`\n",
    "- Falcon 9 rockets which have landpad name is `JRTI`, and landpad type is `ASDS` => landpad region `Florida`\n",
    "- Falcon 9 rockets which have landpad name is `ASOG`, and landpad type is `ASDS` => landpad region `Florida`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: What are the further rules you can find?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_landpadregion(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Fill missing value in landpad region in the input dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): input dataframe\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: output dataframe\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    if (df is None):\n",
    "        raise ValueError\n",
    "    \n",
    "    # Create a copy of the dataframe to avoid changing the original\n",
    "    df_cp = df.copy()\n",
    "\n",
    "    return df_cp\n",
    "\n",
    "cate_col_df = fill_landpadregion(cate_col_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_info_df = cate_col_df.agg([missing_ratio, num_values, value_ratios])\n",
    "cat_col_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "cat_col_info_df = cate_col_df.agg([missing_ratio, num_values, value_ratios])\n",
    "\n",
    "c = cat_col_info_df['landpad_name']\n",
    "assert adler32(str(c.loc['missing_ratio']).encode()) == 18808975\n",
    "assert adler32(str(c.loc['num_values']).encode()) == 3604535\n",
    "assert adler32(str(c.loc['value_ratios']['LZ-1']).encode()) == 32440521\n",
    "\n",
    "c = cat_col_info_df['landpad_type']\n",
    "assert adler32(str(c.loc['missing_ratio']).encode())  == 18808975\n",
    "assert adler32(str(c.loc['num_values']).encode()) == 3342387\n",
    "assert adler32(str(c.loc['value_ratios']['RTLS']).encode()) == 33226957\n",
    "\n",
    "c = cat_col_info_df['landpad_region']\n",
    "assert adler32(str(c.loc['missing_ratio']).encode()) == 18808975\n",
    "assert adler32(str(c.loc['num_values']).encode()) == 3342387\n",
    "assert adler32(str(c.loc['value_ratios']['California']).encode()) ==  33751242"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Fill missing values for all `raw_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df[\"payloads\"] = raw_df[\"payloads\"].apply(str2dict)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 01\n",
    "assert raw_df.shape == (152, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 02\n",
    "raw_df.select_dtypes(include=['object']).agg([missing_ratio, num_values, value_ratios])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the `payloads` attributes; you have to check whether they have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_col_df2 = cate_col_df.join(pd.DataFrame(cate_col_df['payloads'].tolist())).drop('payloads', axis=1)  \n",
    "cate_col_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you have to missing values for three columns: `type`, `mass`, and `orbit`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 01: Drop all rows that have NaN values for all three columns or any two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 02: Filling missing values for `cate_col_df2` by dropping `None` values from mass attributes. For more convenience, you should save these rows which have `None` mass values to file named as `unknow_mass_spaceX_launch.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_col_df2[cate_col_df2[\"mass\"].isnull()].to_csv(\"./data/unknow_mass_spaceX_launch.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_col_df2.drop(drop_idx, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "cat_col_info_df2 = cate_col_df2.select_dtypes(include=['object']).agg([missing_ratio, num_values, value_ratios])\n",
    "\n",
    "c = cat_col_info_df2['type']\n",
    "assert adler32(str(c.loc['missing_ratio']).encode()) == 18808975\n",
    "assert adler32(str(c.loc['num_values']).encode()) == 3473461\n",
    "# assert adler32(str(c.loc['value_ratios']['Satellite']).encode()) == 34734285\n",
    "assert adler32(str(c.loc['value_ratios']['Satellite']).encode()) == 34209997\n",
    "\n",
    "# Due to mass should be numerical data type, so this check will be disable\n",
    "# c = cat_col_info_df2['mass']\n",
    "# assert adler32(str(c.loc['missing_ratio']).encode()) == 18808975\n",
    "# # assert adler32(str(c.loc['num_values']).encode()) == 10748012\n",
    "# assert adler32(str(c.loc['num_values']).encode()) == 11141232\n",
    "# # assert adler32(str(c.loc['value_ratios']['9600']).encode()) == 19595417\n",
    "# assert adler32(str(c.loc['value_ratios']['9600']).encode()) == 19726487\n",
    "\n",
    "c = cat_col_info_df2['orbit']\n",
    "assert adler32(str(c.loc['missing_ratio']).encode()) == 18808975\n",
    "assert adler32(str(c.loc['num_values']).encode()) == 9764963\n",
    "assert adler32(str(c.loc['value_ratios']['LEO']).encode()) ==  20185242"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 03: Apply for `raw_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 01: unpack `payloads`\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 02: rename columns `type`, `mass`, and `orbit` to `payloads_type`, `payloads_mass`, and `payloads_orbit`\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 03: drop all rows that have NaN values for all three columns or any two columns.\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 04: Filling missing values for `cate_col_df2` by dropping `None` values from mass attributes\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "cat_col_info_df = raw_df.select_dtypes(include=['object']).agg([missing_ratio, num_values, value_ratios])\n",
    "\n",
    "c = cat_col_info_df['payloads_type']\n",
    "assert adler32(str(c.loc['missing_ratio']).encode()) == 18808975\n",
    "assert adler32(str(c.loc['num_values']).encode()) == 3473461\n",
    "# assert adler32(str(c.loc['value_ratios']['Satellite']).encode()) == 34734285\n",
    "assert adler32(str(c.loc['value_ratios']['Satellite']).encode()) == 34209997\n",
    "\n",
    "# Due to mass should be numerical data type, so this check will be disable\n",
    "# c = cat_col_info_df['payloads_mass']\n",
    "# assert adler32(str(c.loc['missing_ratio']).encode()) == 18808975\n",
    "# # assert adler32(str(c.loc['num_values']).encode()) == 10748012\n",
    "# assert adler32(str(c.loc['num_values']).encode()) == 11141232\n",
    "# # assert adler32(str(c.loc['value_ratios']['9600']).encode()) == 19595417\n",
    "# assert adler32(str(c.loc['value_ratios']['9600']).encode()) == 19726487\n",
    "\n",
    "c = cat_col_info_df['payloads_orbit']\n",
    "assert adler32(str(c.loc['missing_ratio']).encode()) == 18808975\n",
    "assert adler32(str(c.loc['num_values']).encode()) == 9764963\n",
    "assert adler32(str(c.loc['value_ratios']['LEO']).encode()) ==  20185242"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you have to unpack `launchpad_geo` and `landpad_geo` to xy coordinates. **Remember**: drop `launchpad_geo` and `landpad_geo` after unpack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2tuple(s: str) -> tuple:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply str2tuple\n",
    "raw_df[\"launchpad_geo\"] = raw_df[\"launchpad_geo\"].apply(str2tuple)\n",
    "raw_df[\"landpad_geo\"] = raw_df[\"landpad_geo\"].apply(str2tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack\n",
    "raw_df[['launchpad_geo_x', 'launchpad_geo_y']] = pd.DataFrame(raw_df['launchpad_geo'].tolist(), index=raw_df.index)\n",
    "raw_df[['landpad_geo_x', 'landpad_geo_y']] = pd.DataFrame(raw_df['landpad_geo'].tolist(), index=raw_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = raw_df.drop([\"launchpad_geo\", \"landpad_geo\"], axis=1)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorical (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you have to encode your attributes, which have a categorical type. To choose the right encoding method, you have to decide if a given attribute is `ordinal` or `nominal`. For `ordinal` attributes, you should use `one hot encoding`, and for `nominal` attributes, you should use `label encoding`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 01: `launch_name` checking, is this `ordinal` or `nominal`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 02: `rocket_name` checking, is this `ordinal` or `nominal`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 03: `launchpad_name` checking, is this `ordinal` or `nominal`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 04: `launchpad_region` checking, is this `ordinal` or `nominal`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 05: `landpad_name` checking, is this `ordinal` or `nominal`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 06: `landpad_type` checking, is this `ordinal` or `nominal`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 07: `landpad_region` checking, is this `ordinal` or `nominal`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 08: `outcome` checking, is this `ordinal` or `nominal`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 09: `payloads_type` checking, is this `ordinal` or `nominal`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 10: `payloads_orbit` checking, is this `ordinal` or `nominal`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After encoding for categorical columns, you check again data types, are there any columns whose data types are not suitable for further processing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "# Temporally disabled\n",
    "# dtypes = raw_df.dtypes\n",
    "# int_cols = set(dtypes[(dtypes==np.int32) | (dtypes==np.int64)].index)\n",
    "# assert adler32(str(len(int_cols)).encode()) == 9764963\n",
    "\n",
    "# float_cols = set(dtypes[(dtypes==np.float32) | (dtypes==np.float64)].index)\n",
    "# assert adler32(str(len(float_cols )).encode()) == 3735609"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretization techniques (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first see about your filled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equal Width Discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixed-width discretization is one common type of discretization approach in which the width or size of all the intervals remains the same. Equal-width discretization is a type of unsupervised discretization technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only perform discretization on the `payloads_mass` column. Let’s first plot a histogram for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log(raw_df['payloads_mass']))\n",
    "plt.title(\"Payload mass distribution.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram for the price column shows that our dataset is negatively skewed. We can use discretization on this type of data distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 01: Find the total payloads mass range by subtracting the minimum mass from the maximum mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "# mass_range = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert adler32(str(mass_range).encode()) == 94306658"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 02: Calculate the upper and upper bound for payloads\n",
    "\n",
    "*Hint*: The minimum payloads will be rounded off to floor, while the maximum payloads will be rounded off to ceil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# lower_interval =?\n",
    "# upper_interval =?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert adler32(str(lower_interval).encode()) == 20316314\n",
    "assert adler32(str(upper_interval).encode()) == 52297997"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 3: Set up bins for visualization. We will make **4 bins** (you can understand why we need 4 bins by experimenting with 4 to 10 bins or the equation below). To generate bins, we will begin with the minimum value and then add the bin interval or length to it. To calculate the second interval, add the interval length to the upper limit of the first interval, and so on.\n",
    "\n",
    "$$\n",
    "\\text{no\\_of\\_bins} = \\dfrac{\\max - \\min}{h} = \\dfrac{\\max - \\min}{2 * IQR * n^{-1/3}} = \\dfrac{\\max - \\min}{2 * (Q3 - Q2) * n^{-1/3}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# interval_size =?\n",
    "# total_bins =?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you should give a label for each bin such as `bin_no_1`, `bin_no_2`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And maybe you want to use the Pandas libraries [`cut()` method](https://pandas.pydata.org/docs/reference/api/pandas.cut.html), it allows you to convert the continuous column values to numeric bin values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will test by using a bar plot that shows the frequency of payloads mass in each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "raw_df.groupby('payloads_mass_bins')['payloads_mass'].count().plot.bar()\n",
    "plt.title(\"Payloads mass discreted histogram.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Describe your observation from chart**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equal Frequency Discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equal frequency discretization is a discretization approach in which the bin width is automatically adjusted so that each bin contains exactly the same amount of records and has the same frequency. As a result, the bin intervals will vary. In this part, you'll apply it to the discrete `payloads_mass` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 01: To convert a continuous column into equal frequency discretized bins, you maybe want to use the [\"qcut()\" method](https://pandas.pydata.org/docs/reference/api/pandas.qcut.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 02: Create bin labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 03: Apply the Pandas libraries [`cut()` method](https://pandas.pydata.org/docs/reference/api/pandas.cut.html), it allows you to convert the continuous column values to numeric bin values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will test by using a bar plot that shows the frequency of payloads mass in each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "raw_df.groupby('payloads_mass_bins')['payloads_mass'].count().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus points** Study about K-Means Discretization, and Decision Tree Discretization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE (Optional)\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude \"bins\" for next section\n",
    "raw_df = raw_df.drop([\"payloads_mass_bins\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier handling techniques (1 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some techniques that you can use to handle outliers:\n",
    "- Totally removing the outliers from the dataset.\n",
    "- Treating outliers as missing values, and then apply any techniques to filter them.\n",
    "- Applying discretization techniques to the dataset that will include the outlier along with other data points at the tail.\n",
    "- Capping and replacing them with maximum and minimum values that can be found via some techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Trimming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier trimming is an outlier handling technique that simply removes the outliers beyond a certain threshold value. And the easiest way to determine this threshold value is to use the IQR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s remove the outliers from the `payloads_mass` column of this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 01: Using box plot to visualize the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very lucky, we have no outliers. :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 02: Calculate IQR and determine the lower bound and upper bound for `payloads_mass`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IQR = raw_df[\"payloads_mass\"].quantile(0.75) - raw_df[\"payloads_mass\"].quantile(0.25)\n",
    "\n",
    "lower_payloads_mass_limit = raw_df[\"payloads_mass\"].quantile(0.25) - (IQR * 1.5)\n",
    "upper_payloads_mass_limit = raw_df[\"payloads_mass\"].quantile(0.75) + (IQR * 1.5)\n",
    "\n",
    "print(f\"The lower bound for payloads limitation: {lower_payloads_mass_limit}\")\n",
    "print(f\"The upper bound for payloads limitation: {upper_payloads_mass_limit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 03: Construct rule for trimming outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payloadsmass_outliers = np.where(\n",
    "    raw_df[\"payloads_mass\"] > upper_payloads_mass_limit,\n",
    "    True,\n",
    "    np.where(raw_df[\"payloads_mass\"] < lower_payloads_mass_limit, True, False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 04: Trimming outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdf_without_payloadsmass_outliers = raw_df.loc[~(payloadsmass_outliers), ]\n",
    "\n",
    "raw_df.shape, payloadsmass_outliers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: What are the advantages and disadvantages of outlier trimming?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Capping Using IQR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am very smart to use IQR to demonstrate the above technique, and for this section, I don't have to demonstrate it again. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Tell me, what is the IQR distance normally used to cap outliers via IQR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Capping Using Mean & Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using the IQR method, the upper and lower thresholds for outliers can be calculated via the mean and standard deviation method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 01: Determine the the upper and lower thresholds.\n",
    "\n",
    "`upper_bound` = `mean` + 3 * `sigma`\n",
    "\n",
    "`lower_bound` = `mean` - 3 * `sigma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 02: Construct rule for trimming outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 03: Trimming outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: What are the advantages and disadvantages of using mean and standard deviation? Tell me, what is the quartile distance normally used to cap outliers via mean and standard deviation? Give your explaination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Capping Using Quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, the upper and lower thresholds for outliers can be calculated via quantile information. We can use it to find outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 01: Determine the the upper and lower thresholds.\n",
    "\n",
    "`upper_bound` = `quantile` 90%\n",
    "\n",
    "`lower_bound` = `quantile` 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 02: Construct rule for trimming outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 03: Trimming outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: What are the advantages and disadvantages of using Quantiles?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling techniques (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you know, in any dataset, there are also many different attributes. And the attributes can have different magnitudes, and statistical information includes variances, standard deviations, mean values, etc. The difference in the scale or magnitude of attributes can actually affect statistical models, such as:\n",
    "- The dominance of large-scale variables\n",
    "- Gradient descent algorithm for convergence\n",
    "- Eclidean distance affects similarity among features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I give you some techniques that can be applied in some situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization is the processing of centering the variable at zero and standardizing the data variance to 1. Now, I will you an example for numerical variable in `raw_df` and visualize on `payloads_mass` attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 01: Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 02: Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(raw_df.drop([\"uct_time\"], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 03: Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df_scaled = scaler.transform(raw_df.drop([\"uct_time\"], axis=1))\n",
    "raw_df_scaled = pd.DataFrame(raw_df_scaled, columns = raw_df.drop([\"uct_time\"], axis=1).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 04: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "raw_df[\"payloads_mass\"].plot(kind=\"kde\", ax=axes[0], color=\"red\")\n",
    "axes[0].set_title(\"Payloads mass before using Standardisation\")\n",
    "\n",
    "raw_df_scaled[\"payloads_mass\"].plot(kind=\"kde\", ax=axes[1], color=\"blue\")\n",
    "axes[1].set_title(\"Payloads mass after using Standardisation\")\n",
    "\n",
    "fig.suptitle(\"Comparing payloads mass before - after scaled.\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Describe your observation from chart**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min/Max Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min/max scaling subtracts each value by the minimum value, and then divide the result by the difference of minimum and maximum value in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Use `sckit-learn` for applying min/max scaling to the `payloads_mass` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: After visualizing the results, describe your observation from chart**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean normalization is very similar to min/max scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Tell me what is the difference between mean normalization and min/ max scaling.**\n",
    "\n",
    "*Give your obervation here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Use `sckit-learn` for applying mean normalization to the `payloads_mass` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: After visualizing the results, describe your observation from chart**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Absolute Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum absolute scaling is probably the simplest of all the scaling techniques. In maximum absolute scaling, each data point is simply divided by the maximum value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Use `sckit-learn` for applying maximum absolute scaling to the `payloads_mass` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: After visualizing the results, describe your observation from chart**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median and Quantile Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In median and quantile scaling, the mean of the dataset is subtracted from all the data points, and the result is divided by the difference between the first quartile and the 3rd quartile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Use `sckit-learn` for applying median and quantile scaling to the `payloads_mass` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: After visualizing the results, describe your observation from chart**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Unit Length Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In unit length scaling, a new feature vector is created by dividing feature vector by the Manhattan distance (l1 norm), or by the Euclidian distance (l2 norm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Use `sckit-learn` for applying vector unit length scaling to the `payloads_mass` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: After visualizing the results, describe your observation from chart**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When and where to apply these normalization techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: After these a bund of normalization techniques, tell me when and where to apply these normalization techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of your lab 01."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
